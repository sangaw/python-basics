{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Code to parse Azure cloud service data\n",
    "\n",
    "This implementation includes several key features:\n",
    "Web Scraping: Uses requests and BeautifulSoup4 to fetch and parse the Azure VM availability documentation.\n",
    "Content Processing: Removes unnecessary HTML elements, Organizes content into sections based on headers, Maintains the structure of the documentation\n",
    "Question Answering: Uses BERT model fine-tuned on SQuAD (Stanford Question Answering Dataset), Finds the most relevant section for each question, Generates answers based on the context\n",
    "Interactive Interface: Provides a simple command-line chat interface, Allows users to ask questions until they choose to quit\n",
    "To use the chatbot, simply run the script and start asking questions about Azure VM availability. For example:\n",
    "\n",
    "# Example usage\n",
    "chatbot = AzureVMDocChatbot()\n",
    "\n",
    "# Ask questions\n",
    "print(chatbot.answer_question(\"What are availability zones in Azure?\"))\n",
    "print(chatbot.answer_question(\"How does Azure Site Recovery help with business continuity?\"))\n",
    "\n",
    "The chatbot will provide answers based on the documentation content. The answers are generated using the BERT model, which understands context and can provide relevant responses based on the documentation.\n",
    "Some example questions you can ask:\n",
    "What are availability zones?\n",
    "How does Azure ensure storage redundancy?\n",
    "What is an availability set?\n",
    "How does Azure Site Recovery work?\n",
    "What is a Virtual Machine Scale Set?\n",
    "Note that the quality of answers depends on:\n",
    "The relevance of the section matching\n",
    "The quality of the question\n",
    "The presence of the information in the documentation\n",
    "You can enhance this implementation by:\n",
    "Adding better error handling\n",
    "Implementing more sophisticated section matching\n",
    "Adding support for follow-up questions\n",
    "Implementing a web interface instead of command-line\n",
    "Adding support for multiple documentation sources\n",
    "Would you like me to explain any particular part of the implementation in more detail?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import required libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/miniconda3/envs/cursor-conda-python-3.11.11/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "\n",
      "A module that was compiled using NumPy 1.x cannot be run in\n",
      "NumPy 2.0.1 as it may crash. To support both 1.x and 2.x\n",
      "versions of NumPy, modules must be compiled with NumPy 2.0.\n",
      "Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.\n",
      "\n",
      "If you are a user of the module, the easiest solution will be to\n",
      "downgrade to 'numpy<2' or try to upgrade the affected module.\n",
      "We expect that some modules will need time to support NumPy 2.\n",
      "\n",
      "Traceback (most recent call last):  File \"<frozen runpy>\", line 198, in _run_module_as_main\n",
      "  File \"<frozen runpy>\", line 88, in _run_code\n",
      "  File \"/opt/miniconda3/envs/cursor-conda-python-3.11.11/lib/python3.11/site-packages/ipykernel_launcher.py\", line 18, in <module>\n",
      "    app.launch_new_instance()\n",
      "  File \"/opt/miniconda3/envs/cursor-conda-python-3.11.11/lib/python3.11/site-packages/traitlets/config/application.py\", line 1075, in launch_instance\n",
      "    app.start()\n",
      "  File \"/opt/miniconda3/envs/cursor-conda-python-3.11.11/lib/python3.11/site-packages/ipykernel/kernelapp.py\", line 739, in start\n",
      "    self.io_loop.start()\n",
      "  File \"/opt/miniconda3/envs/cursor-conda-python-3.11.11/lib/python3.11/site-packages/tornado/platform/asyncio.py\", line 205, in start\n",
      "    self.asyncio_loop.run_forever()\n",
      "  File \"/opt/miniconda3/envs/cursor-conda-python-3.11.11/lib/python3.11/asyncio/base_events.py\", line 608, in run_forever\n",
      "    self._run_once()\n",
      "  File \"/opt/miniconda3/envs/cursor-conda-python-3.11.11/lib/python3.11/asyncio/base_events.py\", line 1936, in _run_once\n",
      "    handle._run()\n",
      "  File \"/opt/miniconda3/envs/cursor-conda-python-3.11.11/lib/python3.11/asyncio/events.py\", line 84, in _run\n",
      "    self._context.run(self._callback, *self._args)\n",
      "  File \"/opt/miniconda3/envs/cursor-conda-python-3.11.11/lib/python3.11/site-packages/ipykernel/kernelbase.py\", line 545, in dispatch_queue\n",
      "    await self.process_one()\n",
      "  File \"/opt/miniconda3/envs/cursor-conda-python-3.11.11/lib/python3.11/site-packages/ipykernel/kernelbase.py\", line 534, in process_one\n",
      "    await dispatch(*args)\n",
      "  File \"/opt/miniconda3/envs/cursor-conda-python-3.11.11/lib/python3.11/site-packages/ipykernel/kernelbase.py\", line 437, in dispatch_shell\n",
      "    await result\n",
      "  File \"/opt/miniconda3/envs/cursor-conda-python-3.11.11/lib/python3.11/site-packages/ipykernel/ipkernel.py\", line 362, in execute_request\n",
      "    await super().execute_request(stream, ident, parent)\n",
      "  File \"/opt/miniconda3/envs/cursor-conda-python-3.11.11/lib/python3.11/site-packages/ipykernel/kernelbase.py\", line 778, in execute_request\n",
      "    reply_content = await reply_content\n",
      "  File \"/opt/miniconda3/envs/cursor-conda-python-3.11.11/lib/python3.11/site-packages/ipykernel/ipkernel.py\", line 449, in do_execute\n",
      "    res = shell.run_cell(\n",
      "  File \"/opt/miniconda3/envs/cursor-conda-python-3.11.11/lib/python3.11/site-packages/ipykernel/zmqshell.py\", line 549, in run_cell\n",
      "    return super().run_cell(*args, **kwargs)\n",
      "  File \"/opt/miniconda3/envs/cursor-conda-python-3.11.11/lib/python3.11/site-packages/IPython/core/interactiveshell.py\", line 3047, in run_cell\n",
      "    result = self._run_cell(\n",
      "  File \"/opt/miniconda3/envs/cursor-conda-python-3.11.11/lib/python3.11/site-packages/IPython/core/interactiveshell.py\", line 3102, in _run_cell\n",
      "    result = runner(coro)\n",
      "  File \"/opt/miniconda3/envs/cursor-conda-python-3.11.11/lib/python3.11/site-packages/IPython/core/async_helpers.py\", line 128, in _pseudo_sync_runner\n",
      "    coro.send(None)\n",
      "  File \"/opt/miniconda3/envs/cursor-conda-python-3.11.11/lib/python3.11/site-packages/IPython/core/interactiveshell.py\", line 3306, in run_cell_async\n",
      "    has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n",
      "  File \"/opt/miniconda3/envs/cursor-conda-python-3.11.11/lib/python3.11/site-packages/IPython/core/interactiveshell.py\", line 3489, in run_ast_nodes\n",
      "    if await self.run_code(code, result, async_=asy):\n",
      "  File \"/opt/miniconda3/envs/cursor-conda-python-3.11.11/lib/python3.11/site-packages/IPython/core/interactiveshell.py\", line 3549, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"/var/folders/gy/xs43v__d0mn25qy5kzxrnkrm0000gn/T/ipykernel_45385/1526344811.py\", line 4, in <module>\n",
      "    from transformers import AutoTokenizer, AutoModelForQuestionAnswering\n",
      "  File \"/opt/miniconda3/envs/cursor-conda-python-3.11.11/lib/python3.11/site-packages/transformers/__init__.py\", line 26, in <module>\n",
      "    from . import dependency_versions_check\n",
      "  File \"/opt/miniconda3/envs/cursor-conda-python-3.11.11/lib/python3.11/site-packages/transformers/dependency_versions_check.py\", line 16, in <module>\n",
      "    from .utils.versions import require_version, require_version_core\n",
      "  File \"/opt/miniconda3/envs/cursor-conda-python-3.11.11/lib/python3.11/site-packages/transformers/utils/__init__.py\", line 27, in <module>\n",
      "    from .chat_template_utils import DocstringParsingException, TypeHintParsingException, get_json_schema\n",
      "  File \"/opt/miniconda3/envs/cursor-conda-python-3.11.11/lib/python3.11/site-packages/transformers/utils/chat_template_utils.py\", line 40, in <module>\n",
      "    from torch import Tensor\n",
      "  File \"/opt/miniconda3/envs/cursor-conda-python-3.11.11/lib/python3.11/site-packages/torch/__init__.py\", line 1477, in <module>\n",
      "    from .functional import *  # noqa: F403\n",
      "  File \"/opt/miniconda3/envs/cursor-conda-python-3.11.11/lib/python3.11/site-packages/torch/functional.py\", line 9, in <module>\n",
      "    import torch.nn.functional as F\n",
      "  File \"/opt/miniconda3/envs/cursor-conda-python-3.11.11/lib/python3.11/site-packages/torch/nn/__init__.py\", line 1, in <module>\n",
      "    from .modules import *  # noqa: F403\n",
      "  File \"/opt/miniconda3/envs/cursor-conda-python-3.11.11/lib/python3.11/site-packages/torch/nn/modules/__init__.py\", line 35, in <module>\n",
      "    from .transformer import TransformerEncoder, TransformerDecoder, \\\n",
      "  File \"/opt/miniconda3/envs/cursor-conda-python-3.11.11/lib/python3.11/site-packages/torch/nn/modules/transformer.py\", line 20, in <module>\n",
      "    device: torch.device = torch.device(torch._C._get_default_device()),  # torch.device('cpu'),\n",
      "/opt/miniconda3/envs/cursor-conda-python-3.11.11/lib/python3.11/site-packages/torch/nn/modules/transformer.py:20: UserWarning: Failed to initialize NumPy: _ARRAY_API not found (Triggered internally at /Users/runner/work/pytorch/pytorch/pytorch/torch/csrc/utils/tensor_numpy.cpp:84.)\n",
      "  device: torch.device = torch.device(torch._C._get_default_device()),  # torch.device('cpu'),\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "from transformers import AutoTokenizer, AutoModelForQuestionAnswering\n",
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "import logging"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__main__:Loading BERT model and tokenizer...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing chatbot...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-large-uncased-whole-word-masking-finetuned-squad were not used when initializing BertForQuestionAnswering: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight']\n",
      "- This IS expected if you are initializing BertForQuestionAnswering from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForQuestionAnswering from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "INFO:__main__:Model loaded successfully in 3.18 seconds!\n",
      "INFO:__main__:Fetching documentation from https://learn.microsoft.com/en-us/azure/virtual-machines/availability\n",
      "INFO:__main__:Fetched document in 0.56 seconds\n",
      "INFO:__main__:Parsing content...\n",
      "INFO:__main__:Found 8 sections to parse\n",
      "Parsing sections: 100%|██████████| 8/8 [00:00<00:00, 3505.48it/s]\n",
      "INFO:__main__:Successfully parsed 8 sections in 0.10 seconds!\n",
      "INFO:__main__:\n",
      "First few sections found:\n",
      "INFO:__main__:1. Availability options for Azure Virtual Machines\n",
      "INFO:__main__:2. Availability zones\n",
      "INFO:__main__:3. Virtual Machines Scale Sets\n",
      "INFO:__main__:\n",
      "Processing question: What are availability zones?\n",
      "INFO:__main__:Searching for relevant section...\n",
      "INFO:__main__:Found relevant section in 0.00 seconds\n",
      "INFO:__main__:Generating answer...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Testing question: What are availability zones?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__main__:Answer generated in 7.04 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer: a physically separate zone, within an azure region\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "class AzureVMDocChatbot:\n",
    "    def __init__(self, timeout=30):  # Add timeout parameter\n",
    "        self.url = \"https://learn.microsoft.com/en-us/azure/virtual-machines/availability\"\n",
    "        self.doc_content = \"\"\n",
    "        self.sections = {}\n",
    "        self.timeout = timeout\n",
    "        \n",
    "        # Set up logging\n",
    "        logging.basicConfig(level=logging.INFO)\n",
    "        self.logger = logging.getLogger(__name__)\n",
    "        \n",
    "        # Initialize the model and tokenizer with progress feedback\n",
    "        self.logger.info(\"Loading BERT model and tokenizer...\")\n",
    "        start_time = time.time()\n",
    "        try:\n",
    "            self.tokenizer = AutoTokenizer.from_pretrained(\n",
    "                \"bert-large-uncased-whole-word-masking-finetuned-squad\",\n",
    "                local_files_only=False  # Allow downloading if not cached\n",
    "            )\n",
    "            self.model = AutoModelForQuestionAnswering.from_pretrained(\n",
    "                \"bert-large-uncased-whole-word-masking-finetuned-squad\",\n",
    "                local_files_only=False\n",
    "            )\n",
    "            self.logger.info(f\"Model loaded successfully in {time.time() - start_time:.2f} seconds!\")\n",
    "        except Exception as e:\n",
    "            self.logger.error(f\"Error loading model: {str(e)}\")\n",
    "            raise\n",
    "\n",
    "        # Load and parse the content\n",
    "        self.load_and_parse_content()\n",
    "\n",
    "    def load_and_parse_content(self):\n",
    "        \"\"\"Fetch and parse the Azure VM documentation with timeout and progress indicators.\"\"\"\n",
    "        try:\n",
    "            self.logger.info(f\"Fetching documentation from {self.url}\")\n",
    "            start_time = time.time()\n",
    "            \n",
    "            # Use timeout for the request\n",
    "            response = requests.get(self.url, timeout=self.timeout)\n",
    "            response.raise_for_status()\n",
    "            \n",
    "            fetch_time = time.time() - start_time\n",
    "            self.logger.info(f\"Fetched document in {fetch_time:.2f} seconds\")\n",
    "            \n",
    "            self.logger.info(\"Parsing content...\")\n",
    "            parse_start_time = time.time()\n",
    "            \n",
    "            soup = BeautifulSoup(response.text, 'html.parser')\n",
    "            \n",
    "            # Extract main content\n",
    "            main_content = soup.find('main')\n",
    "            if main_content:\n",
    "                # Remove unnecessary elements\n",
    "                for element in main_content.find_all(['script', 'style', 'nav']):\n",
    "                    element.decompose()\n",
    "                \n",
    "                # Extract text content\n",
    "                self.doc_content = main_content.get_text(separator=' ', strip=True)\n",
    "                \n",
    "                # Parse sections with progress bar\n",
    "                headers = main_content.find_all(['h1', 'h2', 'h3'])\n",
    "                self.logger.info(f\"Found {len(headers)} sections to parse\")\n",
    "                \n",
    "                current_section = \"\"\n",
    "                current_content = []\n",
    "                \n",
    "                for header in tqdm(headers, desc=\"Parsing sections\"):\n",
    "                    if current_section:\n",
    "                        self.sections[current_section] = ' '.join(current_content)\n",
    "                    current_section = header.get_text(strip=True)\n",
    "                    current_content = []\n",
    "                    \n",
    "                    next_element = header.find_next_sibling()\n",
    "                    while next_element and not next_element.name in ['h1', 'h2', 'h3']:\n",
    "                        if next_element.get_text(strip=True):\n",
    "                            current_content.append(next_element.get_text(strip=True))\n",
    "                        next_element = next_element.find_next_sibling()\n",
    "                \n",
    "                # Add the last section\n",
    "                if current_section:\n",
    "                    self.sections[current_section] = ' '.join(current_content)\n",
    "                \n",
    "                parse_time = time.time() - parse_start_time\n",
    "                self.logger.info(f\"Successfully parsed {len(self.sections)} sections in {parse_time:.2f} seconds!\")\n",
    "                \n",
    "                # Print first few sections as verification\n",
    "                self.logger.info(\"\\nFirst few sections found:\")\n",
    "                for i, (section, _) in enumerate(list(self.sections.items())[:3]):\n",
    "                    self.logger.info(f\"{i+1}. {section}\")\n",
    "                    \n",
    "        except requests.Timeout:\n",
    "            self.logger.error(f\"Timeout error: Request took longer than {self.timeout} seconds\")\n",
    "            raise\n",
    "        except requests.RequestException as e:\n",
    "            self.logger.error(f\"Error fetching documentation: {str(e)}\")\n",
    "            raise\n",
    "        except Exception as e:\n",
    "            self.logger.error(f\"Error parsing content: {str(e)}\")\n",
    "            raise\n",
    "\n",
    "    def find_most_relevant_section(self, question):\n",
    "        \"\"\"Find the most relevant section for the given question.\"\"\"\n",
    "        max_score = 0\n",
    "        best_section = None\n",
    "        \n",
    "        self.logger.info(\"Searching for relevant section...\")\n",
    "        start_time = time.time()\n",
    "        \n",
    "        for section, content in self.sections.items():\n",
    "            # Simple relevance scoring based on word overlap\n",
    "            question_words = set(question.lower().split())\n",
    "            section_words = set(section.lower().split() + content.lower().split())\n",
    "            score = len(question_words.intersection(section_words))\n",
    "            \n",
    "            if score > max_score:\n",
    "                max_score = score\n",
    "                best_section = content\n",
    "        \n",
    "        search_time = time.time() - start_time\n",
    "        self.logger.info(f\"Found relevant section in {search_time:.2f} seconds\")\n",
    "        return best_section\n",
    "\n",
    "    def answer_question(self, question):\n",
    "        \"\"\"Answer a question about Azure VM availability.\"\"\"\n",
    "        self.logger.info(f\"\\nProcessing question: {question}\")\n",
    "        start_time = time.time()\n",
    "        \n",
    "        # Find the most relevant section\n",
    "        context = self.find_most_relevant_section(question)\n",
    "        if not context:\n",
    "            return \"I'm sorry, I couldn't find relevant information to answer your question.\"\n",
    "\n",
    "        # Prepare the input for the model\n",
    "        self.logger.info(\"Generating answer...\")\n",
    "        inputs = self.tokenizer(question, context, return_tensors=\"pt\", max_length=512, truncation=True)\n",
    "        \n",
    "        # Get the answer\n",
    "        with torch.no_grad():\n",
    "            outputs = self.model(**inputs)\n",
    "        \n",
    "        # Process the model output\n",
    "        answer_start = torch.argmax(outputs.start_logits)\n",
    "        answer_end = torch.argmax(outputs.end_logits)\n",
    "        \n",
    "        tokens = self.tokenizer.convert_ids_to_tokens(inputs[\"input_ids\"][0])\n",
    "        answer = tokens[answer_start:answer_end + 1]\n",
    "        \n",
    "        # Convert tokens to string\n",
    "        answer = self.tokenizer.convert_tokens_to_string(answer)\n",
    "        \n",
    "        total_time = time.time() - start_time\n",
    "        self.logger.info(f\"Answer generated in {total_time:.2f} seconds\")\n",
    "        \n",
    "        return answer if answer else \"I'm sorry, I couldn't generate a good answer for that question.\"\n",
    "\n",
    "# Test the improved implementation\n",
    "def test_chatbot():\n",
    "    print(\"Initializing chatbot...\")\n",
    "    chatbot = AzureVMDocChatbot(timeout=30)  # Set 30-second timeout\n",
    "    \n",
    "    # Test a simple question\n",
    "    test_question = \"What are availability zones?\"\n",
    "    print(f\"\\nTesting question: {test_question}\")\n",
    "    answer = chatbot.answer_question(test_question)\n",
    "    print(f\"Answer: {answer}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    test_chatbot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__main__:Loading BERT model and tokenizer...\n",
      "Some weights of the model checkpoint at bert-large-uncased-whole-word-masking-finetuned-squad were not used when initializing BertForQuestionAnswering: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight']\n",
      "- This IS expected if you are initializing BertForQuestionAnswering from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForQuestionAnswering from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "INFO:__main__:Model loaded successfully in 1.18 seconds!\n",
      "INFO:__main__:Fetching documentation from https://learn.microsoft.com/en-us/azure/virtual-machines/availability\n",
      "INFO:__main__:Fetched document in 0.21 seconds\n",
      "INFO:__main__:Parsing content...\n",
      "INFO:__main__:Found 8 sections to parse\n",
      "Parsing sections: 100%|██████████| 8/8 [00:00<00:00, 13470.27it/s]\n",
      "INFO:__main__:Successfully parsed 8 sections in 0.05 seconds!\n",
      "INFO:__main__:\n",
      "First few sections found:\n",
      "INFO:__main__:1. Availability options for Azure Virtual Machines\n",
      "INFO:__main__:2. Availability zones\n",
      "INFO:__main__:3. Virtual Machines Scale Sets\n"
     ]
    }
   ],
   "source": [
    "# Cell 3: Initialize the chatbot\n",
    "chatbot = AzureVMDocChatbot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of sections: 8\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Section</th>\n",
       "      <th>Content</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Availability options for Azure Virtual Machines</td>\n",
       "      <td>Article08/22/20249 contributorsFeedback Applie...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Availability zones</td>\n",
       "      <td>Availability zonesexpands the level of control...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Virtual Machines Scale Sets</td>\n",
       "      <td>Azure virtual machine scale setslet you create...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Availability sets</td>\n",
       "      <td>Anavailability setis a logical grouping of VMs...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Load balancer</td>\n",
       "      <td>Combine theAzure Load Balancerwith availabilit...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           Section  \\\n",
       "0  Availability options for Azure Virtual Machines   \n",
       "1                               Availability zones   \n",
       "2                      Virtual Machines Scale Sets   \n",
       "3                                Availability sets   \n",
       "4                                    Load balancer   \n",
       "\n",
       "                                             Content  \n",
       "0  Article08/22/20249 contributorsFeedback Applie...  \n",
       "1  Availability zonesexpands the level of control...  \n",
       "2  Azure virtual machine scale setslet you create...  \n",
       "3  Anavailability setis a logical grouping of VMs...  \n",
       "4  Combine theAzure Load Balancerwith availabilit...  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Cell 4: Visualize the parsed sections\n",
    "sections_df = pd.DataFrame(list(chatbot.sections.items()), columns=['Section', 'Content'])\n",
    "print(f\"Total number of sections: {len(sections_df)}\")\n",
    "sections_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__main__:\n",
      "Processing question: What are availability zones?\n",
      "INFO:__main__:Searching for relevant section...\n",
      "INFO:__main__:Found relevant section in 0.00 seconds\n",
      "INFO:__main__:Generating answer...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Q: What are availability zones?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__main__:Answer generated in 7.51 seconds\n",
      "INFO:__main__:\n",
      "Processing question: How does Azure ensure storage redundancy?\n",
      "INFO:__main__:Searching for relevant section...\n",
      "INFO:__main__:Found relevant section in 0.00 seconds\n",
      "INFO:__main__:Generating answer...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A: a physically separate zone, within an azure region\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "Q: How does Azure ensure storage redundancy?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__main__:Answer generated in 1.56 seconds\n",
      "INFO:__main__:\n",
      "Processing question: What is an availability set?\n",
      "INFO:__main__:Searching for relevant section...\n",
      "INFO:__main__:Found relevant section in 0.00 seconds\n",
      "INFO:__main__:Generating answer...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A: redundancy ensures that your storage account meets its availability and durability targets even in the face of failures\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "Q: What is an availability set?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__main__:Answer generated in 1.27 seconds\n",
      "INFO:__main__:\n",
      "Processing question: How does Azure Site Recovery work?\n",
      "INFO:__main__:Searching for relevant section...\n",
      "INFO:__main__:Found relevant section in 0.00 seconds\n",
      "INFO:__main__:Generating answer...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A: a physically separate zone, within an azure region\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "Q: How does Azure Site Recovery work?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__main__:Answer generated in 1.39 seconds\n",
      "INFO:__main__:\n",
      "Processing question: What is a Virtual Machine Scale Set?\n",
      "INFO:__main__:Searching for relevant section...\n",
      "INFO:__main__:Found relevant section in 0.00 seconds\n",
      "INFO:__main__:Generating answer...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A: replicates workloads running on physical and virtual machines ( vms ) from a primary site to a secondary location\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "Q: What is a Virtual Machine Scale Set?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__main__:Answer generated in 0.93 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A: create and manage a group of load balanced vms\n",
      "--------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Cell 5: Test some example questions\n",
    "test_questions = [\n",
    "    \"What are availability zones?\",\n",
    "    \"How does Azure ensure storage redundancy?\",\n",
    "    \"What is an availability set?\",\n",
    "    \"How does Azure Site Recovery work?\",\n",
    "    \"What is a Virtual Machine Scale Set?\",\n",
    "    \"What is the difference between availability zones and availability sets?\",\n",
    "    \"How many availability zones are there in an Azure region?\",\n",
    "    \"How does Azure Site Recovery help with business continuity?\",  \n",
    "    \"How does Azure Load Balancer work with availability zones?\"\n",
    "]\n",
    "\n",
    "for question in test_questions:\n",
    "    print(f\"\\nQ: {question}\")\n",
    "    print(f\"A: {chatbot.answer_question(question)}\")\n",
    "    print(\"-\" * 80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__main__:\n",
      "Processing question: \n",
      "INFO:__main__:Searching for relevant section...\n",
      "INFO:__main__:Found relevant section in 0.00 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Q: \n",
      "A: I'm sorry, I couldn't find relevant information to answer your question.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Cell 6: Interactive question answering\n",
    "from IPython.display import clear_output\n",
    "\n",
    "def interactive_qa():\n",
    "    while True:\n",
    "        question = input(\"Ask a question (or type 'quit' to exit): \")\n",
    "        if question.lower() == 'quit':\n",
    "            break\n",
    "            \n",
    "        clear_output(wait=True)\n",
    "        print(f\"Q: {question}\")\n",
    "        print(f\"A: {chatbot.answer_question(question)}\")\n",
    "        print(\"\\n\" + \"-\" * 80 + \"\\n\")\n",
    "\n",
    "interactive_qa()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cursor-conda-python-3.11.11",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
